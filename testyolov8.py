import cv2
import time
import streamlit as st
import numpy as np

# C·∫•u h√¨nh giao di·ªán
st.title("üìπ ·ª®ng d·ª•ng Theo D√µi Chuy·ªÉn ƒê·ªông")
st.sidebar.header("C·∫•u h√¨nh")

# C√°c thanh tr∆∞·ª£t ƒëi·ªÅu ch·ªânh tham s·ªë
min_contour_area = st.sidebar.slider("Di·ªán t√≠ch vi·ªÅn t·ªïng qu√°t", 50, 1000, 200)
threshold_value = st.sidebar.slider("ƒê·ªô nh·∫°y (Threshold)", 5, 50, 15)
scale_factor = 0.7
blur_size = (11, 11)

# N√∫t ƒëi·ªÅu khi·ªÉn
start_button = st.sidebar.button("üöÄ B·∫Øt ƒë·∫ßu theo d√µi")
stop_button = st.sidebar.button("‚õî D·ª´ng")

# Tr·∫°ng th√°i ch∆∞∆°ng tr√¨nh
st.sidebar.text("Tr·∫°ng th√°i:")
status = st.sidebar.empty()

# Bi·∫øn ki·ªÉm so√°t lu·ªìng video
running = False

# H√†m x·ª≠ l√Ω ph√°t hi·ªán chuy·ªÉn ƒë·ªông
def motion_detection():
    global running
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        st.error("‚ùå Kh√¥ng th·ªÉ m·ªü video!")
        return

    running = True
    status.text("üîç ƒêang theo d√µi chuy·ªÉn ƒë·ªông...")

    # ƒê·ªçc frame ƒë·∫ßu ti√™n
    ret, prev_frame = cap.read()
    if not ret:
        st.error("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc khung h√¨nh!")
        return
    prev_frame = cv2.resize(prev_frame, None, fx=scale_factor, fy=scale_factor)
    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
    prev_gray = cv2.GaussianBlur(prev_gray, blur_size, 0)

    start_time = time.time()
    frame_count = 0

    video_container = st.empty()  # V√πng hi·ªÉn th·ªã video

    while running:
        ret, frame = cap.read()
        if not ret:
            break

        orig_frame = frame.copy()
        frame = cv2.resize(frame, None, fx=scale_factor, fy=scale_factor)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, blur_size, 0)

        # So s√°nh s·ª± kh√°c bi·ªát gi·ªØa hai khung h√¨nh
        delta_frame = cv2.absdiff(prev_gray, gray)
        thresh = cv2.threshold(delta_frame, threshold_value, 255, cv2.THRESH_BINARY)[1]
        thresh = cv2.dilate(thresh, None, iterations=2)
        thresh = cv2.erode(thresh, None, iterations=1)

        # T√¨m c√°c ƒë∆∞·ªùng vi·ªÅn (contours)
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        motion_detected = False

        for contour in contours:
            if cv2.contourArea(contour) < min_contour_area:
                continue
            motion_detected = True
            (x, y, w, h) = cv2.boundingRect(contour)
            scaled_x, scaled_y = int(x / scale_factor), int(y / scale_factor)
            scaled_w, scaled_h = int(w / scale_factor), int(h / scale_factor)
            cv2.rectangle(orig_frame, (scaled_x, scaled_y), 
                          (scaled_x + scaled_w, scaled_y + scaled_h), (0, 255, 0), 2)

        # FPS calculation
        frame_count += 1
        elapsed_time = time.time() - start_time
        fps = frame_count / elapsed_time if elapsed_time > 0 else 0

        # Hi·ªÉn th·ªã FPS v√† tr·∫°ng th√°i chuy·ªÉn ƒë·ªông
        cv2.putText(orig_frame, f"FPS: {fps:.1f}", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(orig_frame, f"Motion: {'YES' if motion_detected else 'NO'}", 
                    (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, 
                    (0, 0, 255) if motion_detected else (0, 255, 0), 2)

        # Hi·ªÉn th·ªã h√¨nh ·∫£nh l√™n Streamlit
        orig_frame = cv2.cvtColor(orig_frame, cv2.COLOR_BGR2RGB)
        video_container.image(orig_frame, channels="RGB", use_container_width=True)

        prev_gray = gray.copy()

    cap.release()
    status.text("‚èπ ƒê√£ d·ª´ng theo d√µi.")
    running = False

# X·ª≠ l√Ω khi nh·∫•n n√∫t
if start_button:
    motion_detection()
elif stop_button:
    running = False
    status.text("‚èπ ƒê√£ d·ª´ng theo d√µi.")

