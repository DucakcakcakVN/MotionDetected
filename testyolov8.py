import cv2
import streamlit as st
import numpy as np

# üöÄ Giao di·ªán Streamlit
st.title("üé• ·ª®ng d·ª•ng Theo D√µi Chuy·ªÉn ƒê·ªông v·ªõi OpenCV")
st.sidebar.write("### C√†i ƒë·∫∑t")

# ƒêi·ªÅu ch·ªânh th√¥ng s·ªë
min_contour_area = st.sidebar.slider("Di·ªán t√≠ch vi·ªÅn t·ªëi thi·ªÉu", 50, 1000, 200)
threshold_value = st.sidebar.slider("ƒê·ªô nh·∫°y ph√°t hi·ªán", 5, 50, 15)
blur_size = (11, 11)  # K√≠ch th∆∞·ªõc b·ªô l·ªçc l√†m m·ªù

# üîÑ Xin quy·ªÅn truy c·∫≠p camera tr∆∞·ªõc khi ch·∫°y
if "camera_permission" not in st.session_state:
    st.session_state.camera_permission = False

if not st.session_state.camera_permission:
    if st.button("üé• B·∫≠t Camera"):
        st.session_state.camera_permission = True
        st.experimental_rerun()

# üö¶ N·∫øu ƒë√£ c·∫•p quy·ªÅn camera, ti·∫øn h√†nh x·ª≠ l√Ω
if st.session_state.camera_permission:
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        st.error("Kh√¥ng th·ªÉ truy c·∫≠p camera. H√£y ki·ªÉm tra l·∫°i k·∫øt n·ªëi!")
    else:
        # B·ªô nh·ªõ ƒë·ªám frame tr∆∞·ªõc
        prev_gray = None

        # Ch·∫°y v√≤ng l·∫∑p ch√≠nh
        stframe = st.empty()  # T·∫°o v√πng hi·ªÉn th·ªã video trong Streamlit
        while True:
            ret, frame = cap.read()
            if not ret:
                st.error("Kh√¥ng th·ªÉ l·∫•y frame t·ª´ camera!")
                break

            # X·ª≠ l√Ω h√¨nh ·∫£nh
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, blur_size, 0)

            if prev_gray is None:
                prev_gray = gray
                continue

            # So s√°nh hai frame ƒë·ªÉ ph√°t hi·ªán chuy·ªÉn ƒë·ªông
            delta_frame = cv2.absdiff(prev_gray, gray)
            thresh = cv2.threshold(delta_frame, threshold_value, 255, cv2.THRESH_BINARY)[1]
            thresh = cv2.dilate(thresh, None, iterations=2)

            # T√¨m contours
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            motion_detected = False
            for contour in contours:
                if cv2.contourArea(contour) < min_contour_area:
                    continue
                motion_detected = True
                (x, y, w, h) = cv2.boundingRect(contour)
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

            # Ghi tr·∫°ng th√°i chuy·ªÉn ƒë·ªông
            status_text = "üö® Ph√°t hi·ªán chuy·ªÉn ƒë·ªông!" if motion_detected else "‚úÖ Kh√¥ng c√≥ chuy·ªÉn ƒë·ªông"
            cv2.putText(frame, status_text, (10, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

            # C·∫≠p nh·∫≠t frame tr∆∞·ªõc
            prev_gray = gray

            # Hi·ªÉn th·ªã h√¨nh ·∫£nh tr√™n Streamlit
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # ƒê·ªïi m√†u BGR -> RGB
            stframe.image(frame, channels="RGB", use_column_width=True)

        # Gi·∫£i ph√≥ng camera sau khi tho√°t
        cap.release()
        cv2.destroyAllWindows()
